"""
Planning tools for foundry-mcp.

Provides MCP tools for task planning and execution utilities,
including plan formatting, phase management, time reporting,
and spec state reconciliation.

Resilience features:
- Circuit breaker for SDD CLI calls (opens after 5 consecutive failures)
- Timing metrics for all tool invocations
- Configurable timeout (default 30s per operation)
"""

import json
import logging
import subprocess
import time
from dataclasses import asdict
from typing import Any, Dict, Optional

from mcp.server.fastmcp import FastMCP

from foundry_mcp.config import ServerConfig
from foundry_mcp.core.responses import success_response, error_response
from foundry_mcp.core.naming import canonical_tool
from foundry_mcp.core.observability import audit_log, get_metrics
from foundry_mcp.core.resilience import (
    CircuitBreaker,
    CircuitBreakerError,
    MEDIUM_TIMEOUT,
)

logger = logging.getLogger(__name__)

# Metrics singleton for planning tools
_metrics = get_metrics()

# Circuit breaker for SDD CLI operations
# Opens after 5 consecutive failures, recovers after 30 seconds
_sdd_cli_breaker = CircuitBreaker(
    name="sdd_cli_planning",
    failure_threshold=5,
    recovery_timeout=30.0,
    half_open_max_calls=3,
)

# Default timeout for CLI operations (30 seconds)
CLI_TIMEOUT: float = MEDIUM_TIMEOUT


def _run_sdd_command(
    cmd: list,
    tool_name: str,
    timeout: float = CLI_TIMEOUT,
) -> subprocess.CompletedProcess:
    """
    Execute an SDD CLI command with circuit breaker protection and timing.

    Args:
        cmd: Command list to execute
        tool_name: Name of the calling tool (for metrics)
        timeout: Timeout in seconds

    Returns:
        CompletedProcess result from subprocess.run

    Raises:
        CircuitBreakerError: If circuit breaker is open
        subprocess.TimeoutExpired: If command times out
        FileNotFoundError: If SDD CLI is not found
    """
    # Check circuit breaker
    if not _sdd_cli_breaker.can_execute():
        status = _sdd_cli_breaker.get_status()
        _metrics.counter(f"planning.{tool_name}", labels={"status": "circuit_open"})
        raise CircuitBreakerError(
            f"SDD CLI circuit breaker is open (retry after {status.get('retry_after_seconds', 0):.1f}s)",
            breaker_name="sdd_cli_planning",
            state=_sdd_cli_breaker.state,
            retry_after=status.get("retry_after_seconds"),
        )

    start_time = time.perf_counter()
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
        )

        # Record success or failure based on return code
        if result.returncode == 0:
            _sdd_cli_breaker.record_success()
        else:
            # Non-zero return code counts as a failure for circuit breaker
            _sdd_cli_breaker.record_failure()

        return result

    except (subprocess.TimeoutExpired, FileNotFoundError) as e:
        # These are infrastructure failures that should trip the circuit breaker
        _sdd_cli_breaker.record_failure()
        raise
    finally:
        # Record timing metrics
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        _metrics.timer(f"planning.{tool_name}.duration_ms", elapsed_ms)


def register_planning_tools(mcp: FastMCP, config: ServerConfig) -> None:
    """
    Register planning tools with the FastMCP server.

    Args:
        mcp: FastMCP server instance
        config: Server configuration
    """

    @canonical_tool(
        mcp,
        canonical_name="plan-format",
    )
    def plan_format(
        spec_id: str,
        task_id: str,
        path: Optional[str] = None,
    ) -> dict:
        """
        Pretty-print a task plan for sharing and review.

        Wraps the SDD CLI format-plan command to generate a human-readable
        formatted output of a task plan, suitable for sharing with team
        members or including in documentation.

        WHEN TO USE:
        - Sharing task plans with team members
        - Generating documentation from task plans
        - Reviewing task structure before implementation
        - Creating readable summaries of complex tasks

        Args:
            spec_id: Specification ID containing the task
            task_id: Task ID to format
            path: Project root path (default: current directory)

        Returns:
            JSON object with formatted plan:
            - formatted: Human-readable plan text
            - task_id: The task ID that was formatted
            - spec_id: The specification ID
        """
        tool_name = "plan_format"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            if not task_id:
                return asdict(error_response(
                    "task_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a task_id parameter",
                ))

            # Build command
            cmd = ["sdd", "format-plan", spec_id, task_id, "--json"]

            if path:
                cmd.extend(["--path", path])

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="plan-format",
                action="format_plan",
                spec_id=spec_id,
                task_id=task_id,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {"formatted": result.stdout}

                # Build response data
                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "task_id": task_id,
                    "formatted": output_data.get("formatted", output_data.get("plan", result.stdout)),
                }

                # Include additional fields if available
                if "title" in output_data:
                    data["title"] = output_data["title"]
                if "status" in output_data:
                    data["status"] = output_data["status"]

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={"status": "success"})

                return asdict(success_response(
                    data=data,
                    message="Plan formatted successfully",
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec and task IDs exist"
                else:
                    error_code = "FORMAT_FAILED"
                    remediation = "Check the spec_id and task_id"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Plan formatting failed",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"Plan formatting timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))

    @canonical_tool(
        mcp,
        canonical_name="phase-list",
    )
    def phase_list(
        spec_id: str,
        path: Optional[str] = None,
    ) -> dict:
        """
        Enumerate all phases in a specification.

        Wraps the SDD CLI list-phases command to return all phases
        in a specification with their completion status and progress.

        WHEN TO USE:
        - Getting an overview of spec structure
        - Checking phase completion status
        - Planning which phase to work on next
        - Understanding spec organization

        Args:
            spec_id: Specification ID to enumerate phases for
            path: Project root path (default: current directory)

        Returns:
            JSON object with phase list:
            - phases: Array of phase objects with id, title, status, progress
            - total_phases: Total number of phases
            - completed_phases: Number of completed phases
        """
        tool_name = "phase_list"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            # Build command
            cmd = ["sdd", "list-phases", spec_id, "--json"]

            if path:
                cmd.extend(["--path", path])

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="phase-list",
                action="list_phases",
                spec_id=spec_id,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {}

                # Build response data
                phases = output_data.get("phases", [])
                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "phases": phases,
                    "total_phases": len(phases),
                    "completed_phases": sum(1 for p in phases if p.get("status") == "completed"),
                }

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={"status": "success"})

                return asdict(success_response(
                    data=data,
                    message=f"Found {len(phases)} phases",
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec_id exists in specs/active or specs/pending"
                else:
                    error_code = "LIST_FAILED"
                    remediation = "Check the spec_id and try again"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Failed to list phases",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"Phase listing timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))

    @canonical_tool(
        mcp,
        canonical_name="phase-check-complete",
    )
    def phase_check_complete(
        spec_id: str,
        phase_id: Optional[str] = None,
        task_id: Optional[str] = None,
        path: Optional[str] = None,
    ) -> dict:
        """
        Verify completion readiness for a phase or spec.

        Wraps the SDD CLI check-complete command to verify whether
        all tasks in a phase or the entire spec are completed and
        ready for sign-off.

        WHEN TO USE:
        - Verifying phase completion before moving to next phase
        - Checking if a spec is ready for final review
        - Validating that all tasks in a scope are done
        - Pre-merge verification of spec completion

        Args:
            spec_id: Specification ID to check
            phase_id: Optional phase ID to limit scope (mutually exclusive with task_id)
            task_id: Optional task ID to limit scope (mutually exclusive with phase_id)
            path: Project root path (default: current directory)

        Returns:
            JSON object with completion status:
            - is_complete: Boolean indicating if scope is fully complete
            - scope: The scope checked (spec, phase, or task)
            - total_tasks: Total tasks in scope
            - completed_tasks: Number of completed tasks
            - pending_tasks: Array of pending task IDs (if any)
            - blocked_tasks: Array of blocked task IDs (if any)
        """
        tool_name = "phase_check_complete"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            # Validate mutual exclusivity
            if phase_id and task_id:
                return asdict(error_response(
                    "phase_id and task_id are mutually exclusive",
                    error_code="INVALID_PARAMS",
                    error_type="validation",
                    remediation="Provide either phase_id or task_id, not both",
                ))

            # Build command
            cmd = ["sdd", "check-complete", spec_id, "--json"]

            if phase_id:
                cmd.extend(["--phase", phase_id])
            elif task_id:
                cmd.extend(["--task", task_id])

            if path:
                cmd.extend(["--path", path])

            # Determine scope for logging
            scope = "spec"
            scope_id = spec_id
            if phase_id:
                scope = "phase"
                scope_id = phase_id
            elif task_id:
                scope = "task"
                scope_id = task_id

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="phase-check-complete",
                action="check_complete",
                spec_id=spec_id,
                scope=scope,
                scope_id=scope_id,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {}

                # Build response data
                total = output_data.get("total_tasks", 0)
                completed = output_data.get("completed_tasks", 0)
                pending = output_data.get("pending_tasks", [])
                blocked = output_data.get("blocked_tasks", [])

                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "scope": scope,
                    "is_complete": output_data.get("is_complete", total > 0 and total == completed),
                    "total_tasks": total,
                    "completed_tasks": completed,
                    "pending_tasks": pending,
                    "blocked_tasks": blocked,
                }

                if phase_id:
                    data["phase_id"] = phase_id
                elif task_id:
                    data["task_id"] = task_id

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={"status": "success", "scope": scope})

                # Craft appropriate message
                if data["is_complete"]:
                    message = f"{scope.title()} is complete ({completed}/{total} tasks)"
                else:
                    remaining = total - completed
                    message = f"{scope.title()} incomplete: {remaining} tasks remaining"

                return asdict(success_response(
                    data=data,
                    message=message,
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec_id (and phase_id/task_id if provided) exists"
                else:
                    error_code = "CHECK_FAILED"
                    remediation = "Check the spec_id and try again"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Failed to check completion",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"Completion check timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))

    @canonical_tool(
        mcp,
        canonical_name="phase-report-time",
    )
    def phase_report_time(
        spec_id: str,
        phase_id: str,
        path: Optional[str] = None,
    ) -> dict:
        """
        Summarize time tracking metrics for a phase.

        Wraps the SDD CLI phase-time command to aggregate estimated
        and actual hours for all tasks in a phase.

        WHEN TO USE:
        - Reviewing time spent on a phase
        - Comparing estimated vs actual hours
        - Planning future phases based on historical data
        - Generating time reports for stakeholders

        Args:
            spec_id: Specification ID containing the phase
            phase_id: Phase ID to report time for
            path: Project root path (default: current directory)

        Returns:
            JSON object with time metrics:
            - estimated_hours: Total estimated hours for phase
            - actual_hours: Total actual hours spent
            - variance_hours: Difference (actual - estimated)
            - variance_percent: Percentage variance
            - task_count: Number of tasks in phase
            - completed_count: Number of completed tasks
        """
        tool_name = "phase_report_time"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            if not phase_id:
                return asdict(error_response(
                    "phase_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a phase_id parameter",
                ))

            # Build command
            cmd = ["sdd", "phase-time", spec_id, phase_id, "--json"]

            if path:
                cmd.extend(["--path", path])

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="phase-report-time",
                action="report_phase_time",
                spec_id=spec_id,
                phase_id=phase_id,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {}

                # Build response data
                estimated = output_data.get("estimated_hours", 0)
                actual = output_data.get("actual_hours", 0)
                variance = actual - estimated
                variance_pct = (variance / estimated * 100) if estimated > 0 else 0

                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "phase_id": phase_id,
                    "estimated_hours": estimated,
                    "actual_hours": actual,
                    "variance_hours": round(variance, 2),
                    "variance_percent": round(variance_pct, 1),
                    "task_count": output_data.get("task_count", 0),
                    "completed_count": output_data.get("completed_count", 0),
                }

                # Include phase title if available
                if "phase_title" in output_data:
                    data["phase_title"] = output_data["phase_title"]

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={"status": "success"})

                return asdict(success_response(
                    data=data,
                    message=f"Phase time: {actual:.1f}h actual / {estimated:.1f}h estimated",
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec_id and phase_id exist"
                else:
                    error_code = "REPORT_FAILED"
                    remediation = "Check the spec_id and phase_id"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Failed to report phase time",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"Phase time report timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))

    @canonical_tool(
        mcp,
        canonical_name="spec-reconcile-state",
    )
    def spec_reconcile_state(
        spec_id: str,
        dry_run: bool = True,
        path: Optional[str] = None,
    ) -> dict:
        """
        Compare filesystem state against spec state to detect drift.

        Wraps the SDD CLI reconcile-state command to detect file changes
        that are not reflected in the specification, helping identify
        when implementations have drifted from the planned work.

        WHEN TO USE:
        - Before resuming work on a spec after a break
        - After manual file edits outside the SDD workflow
        - Verifying spec accurately reflects current codebase state
        - Detecting untracked changes before marking tasks complete

        Args:
            spec_id: Specification ID to reconcile
            dry_run: If True (default), only report drift without making changes
            path: Project root path (default: current directory)

        Returns:
            JSON object with reconciliation results:
            - has_drift: Boolean indicating if drift was detected
            - modified_files: Files changed since spec last updated
            - new_files: Files created but not in spec
            - missing_files: Files in spec but not on filesystem
            - recommendations: Suggested actions to resolve drift
        """
        tool_name = "spec_reconcile_state"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            # Build command
            cmd = ["sdd", "reconcile-state", spec_id, "--json"]

            if dry_run:
                cmd.append("--dry-run")

            if path:
                cmd.extend(["--path", path])

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="spec-reconcile-state",
                action="reconcile_state",
                spec_id=spec_id,
                dry_run=dry_run,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {}

                # Build response data
                modified = output_data.get("modified_files", [])
                new_files = output_data.get("new_files", [])
                missing = output_data.get("missing_files", [])
                has_drift = bool(modified or new_files or missing)

                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "has_drift": has_drift,
                    "dry_run": dry_run,
                    "modified_files": modified,
                    "new_files": new_files,
                    "missing_files": missing,
                    "drift_count": len(modified) + len(new_files) + len(missing),
                }

                # Include recommendations if available
                if "recommendations" in output_data:
                    data["recommendations"] = output_data["recommendations"]

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={
                    "status": "success",
                    "has_drift": str(has_drift).lower(),
                })

                # Craft appropriate message
                if has_drift:
                    message = f"Drift detected: {data['drift_count']} file(s) out of sync"
                else:
                    message = "No drift detected - spec is in sync with filesystem"

                return asdict(success_response(
                    data=data,
                    message=message,
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec_id exists"
                else:
                    error_code = "RECONCILE_FAILED"
                    remediation = "Check the spec_id and try again"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Failed to reconcile state",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"State reconciliation timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))

    @canonical_tool(
        mcp,
        canonical_name="plan-report-time",
    )
    def plan_report_time(
        spec_id: str,
        path: Optional[str] = None,
    ) -> dict:
        """
        Generate a comprehensive time tracking summary for a spec.

        Wraps the SDD CLI time-report command to aggregate time metrics
        across all phases and tasks in a specification.

        WHEN TO USE:
        - Generating project status reports
        - Reviewing overall time spent vs estimated
        - Planning future sprints based on velocity
        - Identifying phases that took longer than expected

        Args:
            spec_id: Specification ID to report time for
            path: Project root path (default: current directory)

        Returns:
            JSON object with time metrics:
            - total_estimated_hours: Sum of all estimated hours
            - total_actual_hours: Sum of all actual hours
            - total_variance_hours: Overall variance (actual - estimated)
            - total_variance_percent: Overall percentage variance
            - phases: Array of per-phase time summaries
            - completion_rate: Percentage of tasks completed
        """
        tool_name = "plan_report_time"
        try:
            # Validate required parameters
            if not spec_id:
                return asdict(error_response(
                    "spec_id is required",
                    error_code="MISSING_REQUIRED",
                    error_type="validation",
                    remediation="Provide a spec_id parameter",
                ))

            # Build command
            cmd = ["sdd", "time-report", spec_id, "--json"]

            if path:
                cmd.extend(["--path", path])

            # Log the operation
            audit_log(
                "tool_invocation",
                tool="plan-report-time",
                action="report_time",
                spec_id=spec_id,
            )

            # Execute the command with resilience
            result = _run_sdd_command(cmd, tool_name)

            # Parse the JSON output
            if result.returncode == 0:
                try:
                    output_data = json.loads(result.stdout) if result.stdout.strip() else {}
                except json.JSONDecodeError:
                    output_data = {}

                # Build response data
                estimated = output_data.get("total_estimated_hours", 0)
                actual = output_data.get("total_actual_hours", 0)
                variance = actual - estimated
                variance_pct = (variance / estimated * 100) if estimated > 0 else 0

                data: Dict[str, Any] = {
                    "spec_id": spec_id,
                    "total_estimated_hours": estimated,
                    "total_actual_hours": actual,
                    "total_variance_hours": round(variance, 2),
                    "total_variance_percent": round(variance_pct, 1),
                    "phases": output_data.get("phases", []),
                    "total_tasks": output_data.get("total_tasks", 0),
                    "completed_tasks": output_data.get("completed_tasks", 0),
                }

                # Calculate completion rate
                if data["total_tasks"] > 0:
                    data["completion_rate"] = round(
                        data["completed_tasks"] / data["total_tasks"] * 100, 1
                    )
                else:
                    data["completion_rate"] = 0

                # Include spec title if available
                if "spec_title" in output_data:
                    data["spec_title"] = output_data["spec_title"]

                # Track metrics
                _metrics.counter(f"planning.{tool_name}", labels={"status": "success"})

                return asdict(success_response(
                    data=data,
                    message=f"Time report: {actual:.1f}h actual / {estimated:.1f}h estimated ({data['completion_rate']}% complete)",
                ))
            else:
                # Handle specific error cases
                stderr = result.stderr.strip()

                if "not found" in stderr.lower():
                    error_code = "NOT_FOUND"
                    remediation = "Ensure the spec_id exists"
                else:
                    error_code = "REPORT_FAILED"
                    remediation = "Check the spec_id and try again"

                _metrics.counter(f"planning.{tool_name}", labels={"status": "error", "code": error_code})

                return asdict(error_response(
                    stderr or "Failed to generate time report",
                    error_code=error_code,
                    error_type="planning",
                    remediation=remediation,
                ))

        except CircuitBreakerError as e:
            return asdict(error_response(
                str(e),
                error_code="CIRCUIT_OPEN",
                error_type="resilience",
                remediation="Wait for circuit breaker recovery, then retry",
            ))

        except subprocess.TimeoutExpired:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "timeout"})
            return asdict(error_response(
                f"Time report timed out after {CLI_TIMEOUT}s",
                error_code="TIMEOUT",
                error_type="timeout",
                remediation="Try again or check system resources",
            ))

        except FileNotFoundError:
            _metrics.counter(f"planning.{tool_name}", labels={"status": "cli_not_found"})
            return asdict(error_response(
                "SDD CLI not found. Ensure 'sdd' is installed and in PATH",
                error_code="CLI_NOT_FOUND",
                error_type="configuration",
                remediation="Install SDD toolkit: pip install claude-sdd-toolkit",
            ))

        except Exception as e:
            logger.exception(f"Unexpected error in {tool_name}")
            _metrics.counter(f"planning.{tool_name}", labels={"status": "error"})
            return asdict(error_response(
                f"Unexpected error: {str(e)}",
                error_code="INTERNAL_ERROR",
                error_type="internal",
                remediation="Check logs for details",
            ))
