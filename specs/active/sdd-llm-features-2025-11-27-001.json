{
  "spec_id": "sdd-llm-features-2025-11-27-001",
  "title": "SDD LLM-Powered Features - AI Integration",
  "generated": "2025-11-27T12:00:00Z",
  "last_updated": "2025-11-28T11:43:41.591608Z",
  "metadata": {
    "description": "Implement LLM-powered SDD operations including provider abstraction, review workflows, PR creation, and AI-enhanced documentation. Requires configurable LLM provider support with graceful degradation.",
    "objectives": [
      "LLM provider abstraction layer supporting OpenAI, Anthropic, and local models",
      "Configurable via TOML config and environment variables",
      "Graceful degradation to data-only mode when no LLM configured",
      "AI-enhanced spec review, PR creation, and documentation generation"
    ],
    "complexity": "high",
    "estimated_hours": 60,
    "assumptions": [
      "Users configure LLM provider via foundry-mcp.toml or environment variables",
      "All LLM operations have data-only fallback mode",
      "Response envelopes use success_response/error_response helpers",
      "LLM timeouts and retries use foundry_mcp.core.resilience patterns",
      "Tool identifiers follow canonical hyphenated names and register via canonical_tool/discovery helpers",
      "LLM tools enforce input hygiene, prompt shielding, observability, and feature-flag gating per docs/mcp_best_practices/04-05-08-11-12-14",
      "Docs plus half_baked_plans/OPERATIONS_TO_ADD.md are updated alongside implementation"
    ],
    "status": "active",
    "activated_date": "2025-11-28T00:02:09.184712Z",
    "progress_percentage": 23,
    "current_phase": "phase-1"
  },
  "hierarchy": {
    "spec-root": {
      "type": "spec",
      "title": "SDD LLM-Powered Features - AI Integration",
      "status": "in_progress",
      "parent": null,
      "children": [
        "phase-1",
        "phase-2",
        "phase-3",
        "phase-4"
      ],
      "total_tasks": 42,
      "completed_tasks": 10,
      "metadata": {}
    },
    "phase-1": {
      "type": "phase",
      "title": "LLM Provider Infrastructure",
      "status": "in_progress",
      "parent": "spec-root",
      "children": [
        "phase-1-files",
        "phase-1-verify"
      ],
      "total_tasks": 15,
      "completed_tasks": 10,
      "metadata": {
        "purpose": "Foundation for all LLM-powered features - provider abstraction and configuration",
        "risk_level": "medium"
      },
      "dependencies": {
        "blocks": [
          "phase-2"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "phase-1-files": {
      "type": "group",
      "title": "File Modifications",
      "status": "in_progress",
      "parent": "phase-1",
      "children": [
        "task-1-1",
        "task-1-2",
        "task-1-3",
        "task-1-4",
        "task-1-5"
      ],
      "total_tasks": 12,
      "completed_tasks": 10,
      "metadata": {},
      "dependencies": {
        "blocks": [
          "phase-1-verify"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-1-1": {
      "type": "task",
      "title": "src/foundry_mcp/core/llm_provider.py",
      "status": "completed",
      "parent": "phase-1-files",
      "children": [
        "task-1-1-1",
        "task-1-1-2",
        "task-1-1-3",
        "task-1-1-4"
      ],
      "total_tasks": 4,
      "completed_tasks": 4,
      "metadata": {
        "file_path": "src/foundry_mcp/core/llm_provider.py",
        "task_category": "implementation",
        "estimated_hours": 8,
        "changes": "Create LLM provider abstraction layer with multiple backend support plus prompt-shielding, observability, and resilience hooks"
      },
      "dependencies": {
        "blocks": [
          "task-1-4",
          "task-1-5"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-1-1-1": {
      "type": "subtask",
      "title": "Define LLMProvider abstract base class",
      "status": "completed",
      "parent": "task-1-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Abstract interface for LLM operations: complete(), chat(), embed()",
        "started_at": "2025-11-28T00:03:28.767598Z",
        "status_note": "Defining LLMProvider abstract base class",
        "completed_at": "2025-11-28T00:05:02.615942Z",
        "needs_journaling": false,
        "actual_hours": 0.026,
        "journaled_at": "2025-11-28T00:05:02.618659Z"
      }
    },
    "task-1-1-2": {
      "type": "subtask",
      "title": "Implement OpenAIProvider",
      "status": "completed",
      "parent": "task-1-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "OpenAI API integration with gpt-4, gpt-3.5-turbo support",
        "started_at": "2025-11-28T00:05:35.442019Z",
        "status_note": "Implementing OpenAI provider",
        "completed_at": "2025-11-28T00:06:41.090142Z",
        "needs_journaling": false,
        "actual_hours": 0.018,
        "journaled_at": "2025-11-28T00:06:41.093479Z"
      }
    },
    "task-1-1-3": {
      "type": "subtask",
      "title": "Implement AnthropicProvider",
      "status": "completed",
      "parent": "task-1-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Anthropic API integration with claude-3-opus, claude-3-sonnet support",
        "started_at": "2025-11-28T00:07:12.817077Z",
        "status_note": "Implementing Anthropic provider",
        "completed_at": "2025-11-28T00:08:27.307081Z",
        "needs_journaling": false,
        "actual_hours": 0.021,
        "journaled_at": "2025-11-28T00:08:27.310087Z"
      }
    },
    "task-1-1-4": {
      "type": "subtask",
      "title": "Implement LocalProvider (ollama/llama.cpp)",
      "status": "completed",
      "parent": "task-1-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Local model support via ollama or llama.cpp API",
        "started_at": "2025-11-28T00:08:58.994388Z",
        "status_note": "Implementing local model provider",
        "completed_at": "2025-11-28T00:10:01.750523Z",
        "needs_journaling": false,
        "actual_hours": 0.017,
        "journaled_at": "2025-11-28T00:10:01.753337Z"
      }
    },
    "task-1-2": {
      "type": "task",
      "title": "src/foundry_mcp/core/llm_config.py",
      "status": "completed",
      "parent": "phase-1-files",
      "children": [
        "task-1-2-1",
        "task-1-2-2",
        "task-1-2-3",
        "task-1-2-4",
        "task-1-2-5"
      ],
      "total_tasks": 5,
      "completed_tasks": 5,
      "metadata": {
        "file_path": "src/foundry_mcp/core/llm_config.py",
        "task_category": "implementation",
        "estimated_hours": 5,
        "changes": "Create LLM configuration loading from TOML and environment variables with validation, secret redaction, feature-flag exposure, and document new [llm]/[workflow] keys in docs/README.md plus samples/foundry-mcp.toml"
      },
      "dependencies": {
        "blocks": [
          "task-1-3",
          "task-1-4",
          "task-1-5"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-1-2-1": {
      "type": "subtask",
      "title": "Implement TOML config parsing for [llm] section",
      "status": "completed",
      "parent": "task-1-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Parse provider, api_key, model, timeout from foundry-mcp.toml",
        "started_at": "2025-11-28T11:29:28.430233Z",
        "status_note": "Starting TOML config parsing implementation",
        "completed_at": "2025-11-28T11:31:06.204198Z",
        "needs_journaling": false,
        "actual_hours": 0.027,
        "journaled_at": "2025-11-28T11:31:06.207308Z"
      }
    },
    "task-1-2-2": {
      "type": "subtask",
      "title": "Implement environment variable fallback",
      "status": "completed",
      "parent": "task-1-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Support FOUNDRY_MCP_LLM_PROVIDER, FOUNDRY_MCP_LLM_API_KEY, etc.",
        "started_at": "2025-11-28T11:31:34.814673Z",
        "status_note": "Updating env var prefix to FOUNDRY_MCP_LLM_*",
        "completed_at": "2025-11-28T11:38:10.784752Z",
        "needs_journaling": false,
        "actual_hours": 0.11,
        "journaled_at": "2025-11-28T11:38:10.788598Z"
      }
    },
    "task-1-2-3": {
      "type": "subtask",
      "title": "Implement workflow mode configuration",
      "status": "completed",
      "parent": "task-1-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Support [workflow] section with mode, auto_validate, journal_enabled",
        "started_at": "2025-11-28T11:38:37.442991Z",
        "status_note": "Adding [workflow] section configuration",
        "completed_at": "2025-11-28T11:39:47.730999Z",
        "needs_journaling": false,
        "actual_hours": 0.02,
        "journaled_at": "2025-11-28T11:39:47.733956Z"
      }
    },
    "task-1-2-4": {
      "type": "subtask",
      "title": "Update docs/README.md with LLM config guidance",
      "status": "completed",
      "parent": "task-1-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Document new [llm]/[workflow] keys, env vars, and feature flag expectations for LLM adapters",
        "started_at": "2025-11-28T11:40:15.652546Z",
        "status_note": "Adding LLM configuration documentation",
        "completed_at": "2025-11-28T11:41:00.896727Z",
        "needs_journaling": false,
        "actual_hours": 0.013,
        "journaled_at": "2025-11-28T11:41:00.899672Z"
      }
    },
    "task-1-2-5": {
      "type": "subtask",
      "title": "Add samples/foundry-mcp.toml illustrating [llm]/[workflow] sections",
      "status": "completed",
      "parent": "task-1-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "details": "Provide canonical sample config with provider/model/timeouts plus workflow mode defaults",
        "started_at": "2025-11-28T11:41:22.997333Z",
        "status_note": "Creating sample TOML config file",
        "completed_at": "2025-11-28T11:42:15.325608Z",
        "needs_journaling": false,
        "actual_hours": 0.015,
        "journaled_at": "2025-11-28T11:42:15.328560Z"
      }
    },
    "task-1-3": {
      "type": "task",
      "title": "src/foundry_mcp/tools/context.py",
      "status": "completed",
      "parent": "phase-1-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-1-2"
        ],
        "depends": [],
        "blocks": [
          "task-1-4"
        ]
      },
      "total_tasks": 1,
      "completed_tasks": 1,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/context.py",
        "task_category": "implementation",
        "estimated_hours": 2,
        "changes": "Implement get-server-context MCP tool for workspace info, exposing negotiated capabilities while masking sensitive config",
        "started_at": "2025-11-28T11:42:37.897868Z",
        "status_note": "Creating context.py with get-server-context MCP tool",
        "completed_at": "2025-11-28T11:43:41.586560Z",
        "needs_journaling": false,
        "actual_hours": 0.018,
        "journaled_at": "2025-11-28T11:43:41.590173Z"
      }
    },
    "task-1-4": {
      "type": "task",
      "title": "src/foundry_mcp/tools/server.py",
      "status": "pending",
      "parent": "phase-1-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-1-1",
          "task-1-2",
          "task-1-3"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/server.py",
        "task_category": "implementation",
        "estimated_hours": 1,
        "changes": "Register context tools and wire up LLM provider with canonical_tool metadata plus discovery/capabilities manifest updates"
      }
    },
    "task-1-5": {
      "type": "task",
      "title": "tests/unit/test_llm_provider.py",
      "status": "pending",
      "parent": "phase-1-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-1-1",
          "task-1-2"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/unit/test_llm_provider.py",
        "task_category": "implementation",
        "estimated_hours": 4,
        "changes": "Create unit tests for LLM provider abstraction and config"
      }
    },
    "phase-1-verify": {
      "type": "group",
      "title": "Verification",
      "status": "pending",
      "parent": "phase-1",
      "children": [
        "verify-1-1",
        "verify-1-2",
        "verify-1-3"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-1-files"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 3,
      "completed_tasks": 0,
      "metadata": {}
    },
    "verify-1-1": {
      "type": "verify",
      "title": "Unit tests pass for LLM provider module",
      "status": "pending",
      "parent": "phase-1-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/unit/test_llm_provider.py -v",
        "expected": "All tests pass including mocked provider calls"
      }
    },
    "verify-1-2": {
      "type": "verify",
      "title": "Graceful degradation without LLM config",
      "status": "pending",
      "parent": "phase-1-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "manual",
        "expected": "LLM-powered tools return data-only responses when no provider configured",
        "command": ""
      },
      "dependencies": {
        "blocks": [],
        "blocked_by": [],
        "depends": []
      }
    },
    "verify-1-3": {
      "type": "verify",
      "title": "Phase 1 implementation fidelity review",
      "status": "pending",
      "parent": "phase-1-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "fidelity",
        "agent": "sdd-fidelity-review",
        "scope": "phase",
        "target": "phase-1"
      }
    },
    "phase-2": {
      "type": "phase",
      "title": "LLM-Powered Review & PR Workflow",
      "status": "pending",
      "parent": "spec-root",
      "children": [
        "phase-2-files",
        "phase-2-verify"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-1"
        ],
        "depends": [],
        "blocks": [
          "phase-3"
        ]
      },
      "total_tasks": 10,
      "completed_tasks": 0,
      "metadata": {
        "purpose": "AI-enhanced review sessions and PR creation capabilities",
        "risk_level": "high"
      }
    },
    "phase-2-files": {
      "type": "group",
      "title": "File Modifications",
      "status": "pending",
      "parent": "phase-2",
      "children": [
        "task-2-1",
        "task-2-2",
        "task-2-3"
      ],
      "total_tasks": 7,
      "completed_tasks": 0,
      "metadata": {},
      "dependencies": {
        "blocks": [
          "phase-2-verify"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-2-1": {
      "type": "task",
      "title": "src/foundry_mcp/tools/review.py",
      "status": "pending",
      "parent": "phase-2-files",
      "children": [
        "task-2-1-1",
        "task-2-1-2",
        "task-2-1-3",
        "task-2-1-4"
      ],
      "total_tasks": 4,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/review.py",
        "task_category": "implementation",
        "estimated_hours": 11,
        "changes": "Create new module with LLM-powered spec review tools that enforce input hygiene, prompt shielding, observability, resilience controls, feature flags, and canonical_tool/discovery metadata"
      },
      "dependencies": {
        "blocks": [
          "task-2-3"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-2-1-1": {
      "type": "subtask",
      "title": "Implement spec-review - interactive or automated spec review sessions",
      "status": "pending",
      "parent": "task-2-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd review, use LLM for intelligent spec analysis and suggestions"
      }
    },
    "task-2-1-2": {
      "type": "subtask",
      "title": "Implement review-list-plan-tools - enumerate review toolchains for plans",
      "status": "pending",
      "parent": "task-2-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd list-plan-review-tools, return available plan review pipelines"
      }
    },
    "task-2-1-3": {
      "type": "subtask",
      "title": "Implement review-list-tools - list available review pipelines",
      "status": "pending",
      "parent": "task-2-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd list-review-tools, return non-plan-focused review options"
      }
    },
    "task-2-1-4": {
      "type": "subtask",
      "title": "Wire resilience/telemetry helpers for review tools",
      "status": "pending",
      "parent": "task-2-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Integrate foundry_mcp/core/resilience.py, core/concurrency.py, and core/observability.py to enforce timeouts, retries, and tracing for all review adapters"
      }
    },
    "task-2-2": {
      "type": "task",
      "title": "src/foundry_mcp/tools/pr_workflow.py",
      "status": "pending",
      "parent": "phase-2-files",
      "children": [
        "task-2-2-1",
        "task-2-2-2"
      ],
      "total_tasks": 2,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/pr_workflow.py",
        "task_category": "implementation",
        "estimated_hours": 9,
        "changes": "Create new module with AI-enhanced PR creation, layering prompt shielding, auditing, resilience hooks, feature flags, and canonical_tool/discovery metadata"
      },
      "dependencies": {
        "blocks": [
          "task-2-3"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-2-2-1": {
      "type": "subtask",
      "title": "Implement pr-create-with-spec - scaffold GitHub PRs with SDD context",
      "status": "pending",
      "parent": "task-2-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd create-pr, use LLM for AI-enhanced PR descriptions from spec metadata"
      }
    },
    "task-2-2-2": {
      "type": "subtask",
      "title": "Apply resilience/telemetry helpers to PR workflow",
      "status": "pending",
      "parent": "task-2-2",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Enforce timeouts, retries, and tracing using core/resilience.py, core/concurrency.py, and core/observability.py for pr-create-with-spec"
      }
    },
    "task-2-3": {
      "type": "task",
      "title": "tests/unit/test_review.py",
      "status": "pending",
      "parent": "phase-2-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-2-1",
          "task-2-2"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/unit/test_review.py",
        "task_category": "implementation",
        "estimated_hours": 4,
        "changes": "Create unit tests for review and PR workflow tools with mocked LLM plus data-only fallback pathways"
      }
    },
    "phase-2-verify": {
      "type": "group",
      "title": "Verification",
      "status": "pending",
      "parent": "phase-2",
      "children": [
        "verify-2-1",
        "verify-2-2",
        "verify-2-3"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-2-files"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 3,
      "completed_tasks": 0,
      "metadata": {}
    },
    "verify-2-1": {
      "type": "verify",
      "title": "Unit tests pass for review module",
      "status": "pending",
      "parent": "phase-2-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/unit/test_review.py -v",
        "expected": "All tests pass with mocked LLM responses"
      }
    },
    "verify-2-2": {
      "type": "verify",
      "title": "Data-only mode works for review tools",
      "status": "pending",
      "parent": "phase-2-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/integration/test_llm_review.py -v -k data_only",
        "expected": "spec-review and pr-create-with-spec pass mocked provider matrix and data-only fallback assertions"
      },
      "dependencies": {
        "blocks": [],
        "blocked_by": [],
        "depends": []
      }
    },
    "verify-2-3": {
      "type": "verify",
      "title": "Phase 2 implementation fidelity review",
      "status": "pending",
      "parent": "phase-2-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "fidelity",
        "agent": "sdd-fidelity-review",
        "scope": "phase",
        "target": "phase-2"
      }
    },
    "phase-3": {
      "type": "phase",
      "title": "LLM-Powered Documentation",
      "status": "pending",
      "parent": "spec-root",
      "children": [
        "phase-3-files",
        "phase-3-verify"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-2"
        ],
        "depends": [],
        "blocks": [
          "phase-4"
        ]
      },
      "total_tasks": 9,
      "completed_tasks": 0,
      "metadata": {
        "purpose": "AI-enhanced documentation generation capabilities",
        "risk_level": "high"
      }
    },
    "phase-3-files": {
      "type": "group",
      "title": "File Modifications",
      "status": "pending",
      "parent": "phase-3",
      "children": [
        "task-3-1",
        "task-3-2",
        "task-3-3"
      ],
      "total_tasks": 6,
      "completed_tasks": 0,
      "metadata": {},
      "dependencies": {
        "blocks": [
          "phase-3-verify"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-3-1": {
      "type": "task",
      "title": "src/foundry_mcp/tools/documentation.py",
      "status": "pending",
      "parent": "phase-3-files",
      "children": [
        "task-3-1-1",
        "task-3-1-2",
        "task-3-1-3",
        "task-3-1-4"
      ],
      "total_tasks": 4,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/documentation.py",
        "task_category": "implementation",
        "estimated_hours": 13,
        "changes": "Create new module with LLM-powered documentation tools including prompt shielding, content validation, discovery/capabilities exposure, and shared resilience/telemetry helpers"
      },
      "dependencies": {
        "blocks": [
          "task-3-2",
          "task-3-3"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-3-1-1": {
      "type": "subtask",
      "title": "Implement spec-doc - generate human-facing documentation bundles",
      "status": "pending",
      "parent": "task-3-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd doc, generate markdown/HTML documentation from spec"
      }
    },
    "task-3-1-2": {
      "type": "subtask",
      "title": "Implement spec-doc-llm - LLM-powered doc generation suite",
      "status": "pending",
      "parent": "task-3-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd llm-doc-gen, use LLM to enhance documentation with context and explanations"
      }
    },
    "task-3-1-3": {
      "type": "subtask",
      "title": "Implement spec-review-fidelity - specialized documentation fidelity checks",
      "status": "pending",
      "parent": "task-3-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Wrap sdd fidelity-review, compare code implementation to spec documentation"
      }
    },
    "task-3-1-4": {
      "type": "subtask",
      "title": "Add resilience/telemetry hooks to documentation tools",
      "status": "pending",
      "parent": "task-3-1",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "details": "Ensure spec-doc, spec-doc-llm, and spec-review-fidelity wrap LLM calls with core/resilience, core/concurrency, and core/observability helpers"
      }
    },
    "task-3-2": {
      "type": "task",
      "title": "src/foundry_mcp/tools/server.py",
      "status": "pending",
      "parent": "phase-3-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-3-1"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/tools/server.py",
        "task_category": "implementation",
        "estimated_hours": 1,
        "changes": "Register documentation tools with FastMCP server, ensure canonical_tool registration, and refresh discovery plus capabilities manifest"
      }
    },
    "task-3-3": {
      "type": "task",
      "title": "tests/unit/test_documentation.py",
      "status": "pending",
      "parent": "phase-3-files",
      "children": [],
      "dependencies": {
        "blocked_by": [
          "task-3-1"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/unit/test_documentation.py",
        "task_category": "implementation",
        "estimated_hours": 4,
        "changes": "Create unit tests for documentation tools with mocked LLM plus data-only fallback snapshots"
      }
    },
    "phase-3-verify": {
      "type": "group",
      "title": "Verification",
      "status": "pending",
      "parent": "phase-3",
      "children": [
        "verify-3-1",
        "verify-3-2",
        "verify-3-3"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-3-files"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 3,
      "completed_tasks": 0,
      "metadata": {}
    },
    "verify-3-1": {
      "type": "verify",
      "title": "Unit tests pass for documentation module",
      "status": "pending",
      "parent": "phase-3-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/unit/test_documentation.py -v",
        "expected": "All tests pass with mocked LLM responses"
      }
    },
    "verify-3-2": {
      "type": "verify",
      "title": "Fidelity review produces actionable output",
      "status": "pending",
      "parent": "phase-3-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/integration/test_llm_docs.py -v -k fidelity",
        "expected": "spec-doc, spec-doc-llm, and spec-review-fidelity emit actionable results with data-only fallback"
      },
      "dependencies": {
        "blocks": [],
        "blocked_by": [],
        "depends": []
      }
    },
    "verify-3-3": {
      "type": "verify",
      "title": "Phase 3 implementation fidelity review",
      "status": "pending",
      "parent": "phase-3-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "fidelity",
        "agent": "sdd-fidelity-review",
        "scope": "phase",
        "target": "phase-3"
      }
    },
    "phase-4": {
      "type": "phase",
      "title": "Integration & Final Verification",
      "status": "pending",
      "parent": "spec-root",
      "children": [
        "phase-4-files",
        "phase-4-verify"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-3"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 8,
      "completed_tasks": 0,
      "metadata": {
        "purpose": "End-to-end integration testing and documentation",
        "risk_level": "medium"
      }
    },
    "phase-4-files": {
      "type": "group",
      "title": "File Modifications",
      "status": "pending",
      "parent": "phase-4",
      "children": [
        "task-4-1",
        "task-4-2",
        "task-4-3",
        "task-4-4",
        "task-4-5"
      ],
      "total_tasks": 5,
      "completed_tasks": 0,
      "metadata": {},
      "dependencies": {
        "blocks": [
          "phase-4-verify"
        ],
        "blocked_by": [],
        "depends": []
      }
    },
    "task-4-1": {
      "type": "task",
      "title": "tests/integration/test_llm_tools.py",
      "status": "pending",
      "parent": "phase-4-files",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/integration/test_llm_tools.py",
        "task_category": "implementation",
        "estimated_hours": 4,
        "changes": "Create integration tests for all LLM-powered tools, including data-only fallback paths and multi-provider matrix"
      }
    },
    "task-4-2": {
      "type": "task",
      "title": "src/foundry_mcp/core/discovery.py",
      "status": "pending",
      "parent": "phase-4-files",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "src/foundry_mcp/core/discovery.py",
        "task_category": "implementation",
        "estimated_hours": 2,
        "changes": "Add discovery metadata for all LLM-powered tools including capability negotiation"
      }
    },
    "task-4-3": {
      "type": "task",
      "title": "docs/llm-integration.md",
      "status": "pending",
      "parent": "phase-4-files",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "docs/llm-integration.md",
        "task_category": "implementation",
        "estimated_hours": 2,
        "changes": "Document LLM configuration, provider options, graceful degradation, and backlog cleanup steps"
      }
    },
    "task-4-4": {
      "type": "task",
      "title": "tests/integration/test_llm_review.py",
      "status": "pending",
      "parent": "phase-4-files",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/integration/test_llm_review.py",
        "task_category": "implementation",
        "estimated_hours": 3,
        "changes": "Add focused integration coverage for spec-review and pr-create-with-spec including mocked provider matrix and data-only fallback assertions"
      }
    },
    "task-4-5": {
      "type": "task",
      "title": "tests/integration/test_llm_docs.py",
      "status": "pending",
      "parent": "phase-4-files",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "file_path": "tests/integration/test_llm_docs.py",
        "task_category": "implementation",
        "estimated_hours": 3,
        "changes": "Add integration coverage for spec-doc, spec-doc-llm, and spec-review-fidelity with provider matrix and graceful degradation checks"
      }
    },
    "phase-4-verify": {
      "type": "group",
      "title": "Verification",
      "status": "pending",
      "parent": "phase-4",
      "children": [
        "verify-4-1",
        "verify-4-2",
        "verify-4-3"
      ],
      "dependencies": {
        "blocked_by": [
          "phase-4-files"
        ],
        "depends": [],
        "blocks": []
      },
      "total_tasks": 3,
      "completed_tasks": 0,
      "metadata": {}
    },
    "verify-4-1": {
      "type": "verify",
      "title": "Integration tests pass",
      "status": "pending",
      "parent": "phase-4-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest tests/integration/test_llm_tools.py tests/integration/test_llm_review.py tests/integration/test_llm_docs.py -v",
        "expected": "All integration suites pass across provider matrix and fallback scenarios"
      }
    },
    "verify-4-2": {
      "type": "verify",
      "title": "Full test suite passes",
      "status": "pending",
      "parent": "phase-4-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "auto",
        "agent": "run-tests",
        "command": "pytest -v",
        "expected": "All tests pass including new LLM tools"
      }
    },
    "verify-4-3": {
      "type": "verify",
      "title": "Spec implementation fidelity review",
      "status": "pending",
      "parent": "phase-4-verify",
      "children": [],
      "total_tasks": 1,
      "completed_tasks": 0,
      "metadata": {
        "verification_type": "fidelity",
        "agent": "sdd-fidelity-review",
        "scope": "spec",
        "target": "spec-root"
      }
    }
  },
  "journal": [
    {
      "timestamp": "2025-11-28T00:05:02.618654Z",
      "entry_type": "status_change",
      "title": "Task Completed: Define LLMProvider abstract base class",
      "author": "claude-code",
      "content": "Created src/foundry_mcp/core/llm_provider.py with LLMProvider abstract base class. Includes: ChatRole/FinishReason enums, ToolCall/ChatMessage/CompletionRequest/ChatRequest/EmbeddingRequest dataclasses, TokenUsage/CompletionResponse/ChatResponse/EmbeddingResponse response types, LLMError hierarchy (RateLimitError, AuthenticationError, InvalidRequestError, ModelNotFoundError, ContentFilterError), and the LLMProvider ABC with abstract methods complete(), chat(), embed() plus default stream_chat(), stream_complete(), count_tokens(), validate_request(), get_model(), and health_check() methods. Import verified.",
      "metadata": {},
      "task_id": "task-1-1-1"
    },
    {
      "timestamp": "2025-11-28T00:06:41.093469Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement OpenAIProvider",
      "author": "claude-code",
      "content": "Implemented OpenAIProvider class with: lazy AsyncOpenAI client initialization, API key from env or param, configurable base_url (for Azure/proxies), complete() using chat API (legacy deprecated), chat() with full tool/function calling support, embed() for text-embedding-3-small, stream_chat() for streaming responses, _handle_api_error() for proper error mapping to LLMError types, _map_finish_reason() for OpenAI reason mapping, and count_tokens() using tiktoken. Import verified.",
      "metadata": {},
      "task_id": "task-1-1-2"
    },
    {
      "timestamp": "2025-11-28T00:08:27.310082Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement AnthropicProvider",
      "author": "claude-code",
      "content": "Implemented AnthropicProvider class with: lazy AsyncAnthropic client initialization, API key from env or param, configurable base_url, _convert_messages() to handle system messages separately and convert tool calls to Anthropic format, complete() using messages API, chat() with full tool/function calling support (OpenAI-style tools converted via _convert_tools()), stream_chat() using client.messages.stream(), embed() raises LLMError (not supported), _map_stop_reason() for Anthropic reason mapping, count_tokens() using anthropic client. Default model: claude-sonnet-4-20250514. Import verified.",
      "metadata": {},
      "task_id": "task-1-1-3"
    },
    {
      "timestamp": "2025-11-28T00:10:01.753332Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement LocalProvider (ollama/llama.cpp)",
      "author": "claude-code",
      "content": "Implemented LocalProvider class for Ollama/llama.cpp support using OpenAI-compatible API. Features: configurable base_url (default http://localhost:11434/v1), default model llama3.2, default embedding model nomic-embed-text, complete()/chat()/embed()/stream_chat() methods using AsyncOpenAI client, helpful error messages for connection failures and missing models, health_check() using Ollama's /api/tags endpoint. Import verified alongside OpenAIProvider and AnthropicProvider.",
      "metadata": {},
      "task_id": "task-1-1-4"
    },
    {
      "timestamp": "2025-11-28T11:31:06.207300Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement TOML config parsing for [llm] section",
      "author": "claude-code",
      "content": "Implemented TOML config parsing for [llm] section in src/foundry_mcp/core/llm_config.py. Created LLMConfig dataclass with fields for provider, api_key, model, timeout, base_url, organization, max_tokens, and temperature. Includes from_toml() and from_dict() class methods for parsing, plus get_api_key() and get_model() methods with defaults. Validation ensures required fields are present. All 1746 existing tests pass. Manual verification confirmed parsing works correctly with test cases for basic instantiation, dict parsing, default models per provider, invalid provider validation, and global config functions.",
      "metadata": {},
      "task_id": "task-1-2-1"
    },
    {
      "timestamp": "2025-11-28T11:38:10.788590Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement environment variable fallback",
      "author": "claude-code",
      "content": "Implemented environment variable fallback for LLM configuration. Updated env var prefix from FOUNDRY_LLM_* to FOUNDRY_MCP_LLM_* for consistency with existing config pattern. Added support for: FOUNDRY_MCP_LLM_PROVIDER, FOUNDRY_MCP_LLM_API_KEY (unified key with priority over provider-specific), FOUNDRY_MCP_LLM_MODEL, FOUNDRY_MCP_LLM_TIMEOUT, FOUNDRY_MCP_LLM_BASE_URL, FOUNDRY_MCP_LLM_MAX_TOKENS, FOUNDRY_MCP_LLM_TEMPERATURE, FOUNDRY_MCP_LLM_ORGANIZATION. get_api_key() now checks priority: explicit api_key > FOUNDRY_MCP_LLM_API_KEY > provider-specific (OPENAI_API_KEY/ANTHROPIC_API_KEY). Invalid env var values handled gracefully with warnings and defaults. Manual verification passed all 6 test cases.",
      "metadata": {},
      "task_id": "task-1-2-2"
    },
    {
      "timestamp": "2025-11-28T11:39:47.733951Z",
      "entry_type": "status_change",
      "title": "Task Completed: Implement workflow mode configuration",
      "author": "claude-code",
      "content": "Implemented [workflow] section configuration in llm_config.py. Created WorkflowMode enum with SINGLE, AUTONOMOUS, and BATCH modes. Created WorkflowConfig dataclass with fields: mode, auto_validate, journal_enabled, batch_size, context_threshold. Implemented from_dict(), from_toml(), and from_env() class methods for parsing. Added validation for batch_size (>=1) and context_threshold (50-100). Environment variables supported: FOUNDRY_MCP_WORKFLOW_MODE, FOUNDRY_MCP_WORKFLOW_AUTO_VALIDATE, FOUNDRY_MCP_WORKFLOW_JOURNAL_ENABLED, FOUNDRY_MCP_WORKFLOW_BATCH_SIZE, FOUNDRY_MCP_WORKFLOW_CONTEXT_THRESHOLD. Added global config functions: get_workflow_config(), set_workflow_config(), reset_workflow_config(). All 1746 existing tests pass. Manual verification passed all 7 test cases.",
      "metadata": {},
      "task_id": "task-1-2-3"
    },
    {
      "timestamp": "2025-11-28T11:41:00.899668Z",
      "entry_type": "status_change",
      "title": "Task Completed: Update docs/README.md with LLM config guidance",
      "author": "claude-code",
      "content": "Updated README.md with comprehensive LLM and Workflow configuration documentation. Added new sections: 'LLM Configuration' documenting [llm] TOML section with provider, api_key, model, timeout, base_url, max_tokens, temperature fields. Added LLM environment variables table with FOUNDRY_MCP_LLM_* vars. Documented provider-specific API key fallbacks (OPENAI_API_KEY, ANTHROPIC_API_KEY). Added 'Workflow Configuration' documenting [workflow] TOML section with mode, auto_validate, journal_enabled, batch_size, context_threshold fields. Documented all three workflow modes (single, autonomous, batch). Added workflow environment variables table with FOUNDRY_MCP_WORKFLOW_* vars.",
      "metadata": {},
      "task_id": "task-1-2-4"
    },
    {
      "timestamp": "2025-11-28T11:42:15.328556Z",
      "entry_type": "status_change",
      "title": "Task Completed: Add samples/foundry-mcp.toml illustrating [llm]/[workflow] sections",
      "author": "claude-code",
      "content": "Created samples/foundry-mcp.toml with comprehensive configuration examples. File includes all configuration sections: [workspace], [logging], [auth], [server], [llm], and [workflow]. Documents configuration priority (env > toml > defaults). LLM section shows provider, api_key, model, timeout, base_url, organization, max_tokens, temperature options with explanatory comments. Workflow section shows mode, auto_validate, journal_enabled, batch_size, context_threshold with descriptions. Includes provider-specific example configurations for OpenAI, Anthropic, and Local (Ollama). Verified sample parses correctly with both LLMConfig and WorkflowConfig classes.",
      "metadata": {},
      "task_id": "task-1-2-5"
    },
    {
      "timestamp": "2025-11-28T11:43:41.590166Z",
      "entry_type": "status_change",
      "title": "Task Completed: src/foundry_mcp/tools/context.py",
      "author": "claude-code",
      "content": "Created src/foundry_mcp/tools/context.py implementing get-server-context MCP tool. Provides server capabilities, workspace info, LLM config, and workflow config. Implements sensitive data masking (_mask_sensitive_value) for API keys showing only first 4 chars. Added _get_llm_config_safe() and _get_workflow_config_safe() helper functions. get-server-context tool has optional include flags for llm, workflow, workspace, capabilities sections. Also added get-llm-status tool for quick LLM provider health check. Uses circuit breaker pattern for resilience. Verified module imports correctly and masking/config retrieval works.",
      "metadata": {},
      "task_id": "task-1-3"
    }
  ]
}